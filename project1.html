<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Project 1</title>
  <style>
    /* General styles */
    body {
      margin: 0;
      padding: 0;
      color: #fff;
      font-family: Arial, sans-serif;
      line-height: 1.6;
      background-color: black; /* Set background color to black */
      background-image: url('https://images.unsplash.com/photo-1519996937440-e9e4edc9b00b'); /* Add background image */
      background-size: cover;
      background-position: center;
    }

    header {
      background-color: rgba(0, 0, 0, 0.5);
      padding: 20px;
      text-align: center;
    }

    nav ul {
      list-style: none;
      padding: 0;
      margin: 0;
    }

    nav ul li {
      display: inline;
      margin-right: 10px;
    }

    nav ul li a {
      color: #fff;
      text-decoration: none;
    }

    #project-details {
      padding: 20px;
      max-width: 100%;
      margin: 0 auto;
    }

    #project-details h2 {
      margin-bottom: 20px;
    }

    #project-details p {
      margin-bottom: 20px;
      text-align: justify;
    }

    /* Media query for mobile view */
    @media only screen and (max-width: 600px) {
      header {
        padding: 10px;
      }

      nav ul li {
        display: block;
        margin: 5px 0;
      }

      #project-details {
        padding: 10px;
      }
    }
  </style>
</head>
<body>
  <header>
    <h1>Project 1</h1>
    <nav>
      <ul>
        <li><a href="index.html">Home</a></li>
        <li><a href="about.html">About</a></li>
        <li><a href="projects.html">Projects</a></li>
        <li><a href="contact.html">Contact</a></li>
      </ul>
    </nav>
  </header>

  <section id="project-details">
    <h2>
      TITLE: Music Recommendation System based on Speech and Facial Expression
    </h2>
    <p><b>DESCRIPTION:</b> Emotion-based music recommendation is the process of discerning and interpreting human emotions through facial expressions and speech recognition to curate personalized music playlists. The objective is to develop systems capable of comprehending, interpreting, and responding to emotional cues in order to deliver fitting music selections. This field holds significant promise with diverse applications, including enhancing mood regulation, therapeutic interventions, immersive entertainment experiences, and personalized user engagement in streaming platforms. Deep learning techniques, particularly leveraging transfer learning algorithms, have demonstrated effectiveness in constructing models for this purpose. This additionally introduces a real-time implementation of emotion-based music recommendation utilizing a web camera, showcasing its efficacy in providing accurate emotional cues for music selection. The proposed system promises to revolutionize the way we engage with and enjoy music, offering a more personalized and emotionally resonant listening experience.</p>
    <!-- Add more project details as needed -->
  </section>

</body>
</html>
